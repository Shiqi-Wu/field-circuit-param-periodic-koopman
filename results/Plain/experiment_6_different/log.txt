Model: ParamKoopmanWithInputs(
  (dictionary): TrainableDictionary(
    (encoder): Transformer_like_Encoder(
      (input_layer): Linear(in_features=6, out_features=64, bias=True)
      (layers): ModuleList(
        (0-5): 6 x FeedForwardLayerConnection(
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=64, out_features=128, bias=True)
            (w_2): Linear(in_features=128, out_features=64, bias=True)
            (dropout): Dropout(p=0.2, inplace=False)
          )
          (sublayer): SublayerConnection(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.2, inplace=False)
          )
        )
      )
      (output_layer): Linear(in_features=64, out_features=45, bias=True)
    )
  )
  (u_dictionary): TrainableDictionary(
    (encoder): Transformer_like_Encoder(
      (input_layer): Linear(in_features=2, out_features=64, bias=True)
      (layers): ModuleList(
        (0-5): 6 x FeedForwardLayerConnection(
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=64, out_features=64, bias=True)
            (w_2): Linear(in_features=64, out_features=64, bias=True)
            (dropout): Dropout(p=0.2, inplace=False)
          )
          (sublayer): SublayerConnection(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.2, inplace=False)
          )
        )
      )
      (output_layer): Linear(in_features=64, out_features=20, bias=True)
    )
  )
  (A_matrix): ParamMatrix(
    (resnet): ResNet(
      (layer1): Sequential(
        (0): BasicBlock2(
          (fc1): Linear(in_features=2, out_features=16, bias=True)
          (fc2): Linear(in_features=16, out_features=16, bias=True)
          (shortcut): Sequential(
            (0): Linear(in_features=2, out_features=16, bias=True)
          )
        )
      )
      (layer2): Sequential(
        (0): BasicBlock2(
          (fc1): Linear(in_features=16, out_features=32, bias=True)
          (fc2): Linear(in_features=32, out_features=32, bias=True)
          (shortcut): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
          )
        )
      )
      (layer3): Sequential(
        (0): BasicBlock2(
          (fc1): Linear(in_features=32, out_features=64, bias=True)
          (fc2): Linear(in_features=64, out_features=64, bias=True)
          (shortcut): Sequential(
            (0): Linear(in_features=32, out_features=64, bias=True)
          )
        )
      )
      (linear): Linear(in_features=64, out_features=2704, bias=True)
    )
  )
  (B_matrix): ParamMatrix(
    (resnet): ResNet(
      (layer1): Sequential(
        (0): BasicBlock2(
          (fc1): Linear(in_features=2, out_features=16, bias=True)
          (fc2): Linear(in_features=16, out_features=16, bias=True)
          (shortcut): Sequential(
            (0): Linear(in_features=2, out_features=16, bias=True)
          )
        )
      )
      (layer2): Sequential(
        (0): BasicBlock2(
          (fc1): Linear(in_features=16, out_features=32, bias=True)
          (fc2): Linear(in_features=32, out_features=32, bias=True)
          (shortcut): Sequential(
            (0): Linear(in_features=16, out_features=32, bias=True)
          )
        )
      )
      (layer3): Sequential(
        (0): BasicBlock2(
          (fc1): Linear(in_features=32, out_features=64, bias=True)
          (fc2): Linear(in_features=64, out_features=64, bias=True)
          (shortcut): Sequential(
            (0): Linear(in_features=32, out_features=64, bias=True)
          )
        )
      )
      (linear): Linear(in_features=64, out_features=1196, bias=True)
    )
  )
)
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0
)
StepLR: <torch.optim.lr_scheduler.StepLR object at 0x79258c024df0>
Device: cuda
Config: {'save_dir': '/home/shiqi_w/code/field-circuit-param-periodic-koopman/results/Plain/experiment_6_different', 'data_dir': '/home/shiqi_w/code/field-circuit-param-periodic-koopman/data/differentMur', 'step_size': 20, 'sample_step': 1, 'pca_dim': 6, 'inputs_dim': 2, 'params_dim': 2, 'batch_size': 512, 'validation_split': 0.2, 'dictionary_dim': 45, 'dictionary_layers': [64, 128, 6], 'u_dictionary_dim': 20, 'u_layers': [64, 64, 6], 'A_layers': [1, 1, 1], 'B_layers': [1, 1, 1], 'lr': 0.001, 'step_size_lr': 400, 'gamma_lr': 0.9, 'epochs': 7000, 'encoder_type': 'Transformer_like', 'Description': '为了防止过拟合，我减少了operater network的自由度（六层降低为3层），并且我将pca_dim由4改成了6.这里的各项参数看似与5相似但是实验数据进行了增加，并且每条traj都只用了前三分之二，后三分之一留作测试。'}
Dataset_scaler: <src.data.CustomDataset object at 0x79259811bdf0>
Training time for 7000 epoches is: 80720.13s
